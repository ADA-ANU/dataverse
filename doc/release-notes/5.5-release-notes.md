# Dataverse Software 5.5

This release brings new features, enhancements, and bug fixes to the Dataverse Software. Thank you to all of the community members who contributed code, suggestions, bug reports, and other assistance across the project.

## Release Highlights

### Auxiliary Files Accessible Through the UI

Auxiliary Files can now be downloaded from the web interface. Auxiliary files uploaded as type=DP appear under "Differentially Private Statistics" under file level download. The rest appear under "Other Auxiliary Files".

Please note that the auxiliary files feature is experimental and if you don't need it, its API endpoints can be blocked.

### Manifest.txt

Users trying to download a zip file larger than the Dataverse installation's :zipdownloadlimit try to download a zip file that was above the installation's , the user would r

### Metrics API

Users can retrieve new types of metrics and per-collection metrics. The new capabilities are described in the guides. A new version of the [Dataverse Metrics web app](https://github.com/IQSS/dataverse-metrics) adds interactive graphs to display these metrics. Anyone running the existing Dataverse Metrics app will need to upgrade or apply [a small patch](https://github.com/IQSS/dataverse-metrics/pull/60) to continue retrieving metrics from Dataverse instances upgrading to this release. Issue #7177/PR #7178

## Major Use Cases

Newly-supported major use cases in this release include:

- Sort Users. (Issue #xxx, PR #xxx)

## Notes for Dataverse Installation Administrators

### Zip Limit for installations running the external zipper

### Geospatial Metadata Block Updated

The Geospatial metadata block (geospatial.tsv) was updated. Dataverse collection administrators can now add a search facet on their collection pages for the metadata block's "Other" field, so that people searching in their collections can narrow searches using the values entered in that field.

### Extended support for S3 Download Redirects ("Direct Downloads")

If your installation uses S3 for storage and you have "direct downloads" enabled, please note that it will now cover the following download types that were not handled by redirects in the earlier versions: saved originals of tabular data files, cached RData frames, resized thumbnails for image files and other auxiliary files. In other words, all the forms of the file download API that take extra arguments, such as "format" or "imageThumb" - for example:

`/api/access/datafile/12345?format=original`

`/api/access/datafile/:persistentId?persistentId=doi:1234/ABCDE/FGHIJ&imageThumb=true`

etc., that were previously excluded.

Since browsers follow redirects automatically, this change should not in any way affect the web GUI users. However, some API users may experience problems, if they use it in a way that does not expect to receive a redirect response. For example, if a user has a script where they expect to download a saved original of an ingested tabular file with the following command:

`curl https://yourhost.edu/api/access/datafile/12345?format=original > orig.dta`

it will fail to save the file when it receives a 303 (redirect) response instead of 200. So they will need to add "-L" to the command line above, to instruct curl to follow redirects:

`curl -L https://yourhost.edu/api/access/datafile/12345?format=original > orig.dta`

Most of your API users have likely figured it out already, since you enabled S3 redirects for "straightforward" downloads in your installation. But we feel it was worth a heads up, just in case.

### Authenticated User Deactivated Field Updated

The "deactivated" field on the Authenticated User table has been updated to be a non-nullable field. When the field was added in version 5.3 it was set to 'false' in an update script. If for whatever reason that update failed in the 5.3 deploy you will need to re-run it before deploying 5.5. The update query you may need to run is: UPDATE authenticateduser SET deactivated = false WHERE deactivated IS NULL;

## New JVM Options and Database Settings

For installations that were previously running on Dataverse Software 4.x, a number of new JVM options need to be added as part of the upgrade. The JVM Options are enumerated in the detailed upgrade instructions below.

Two new Database settings were added:

- :InstallationName
- :ExportInstallationAsDistributorOnlyWhenNotSet

For an overview of these new options, please see the
[Installation Guide](https://guides.dataverse.org/en/5.4/installation/config.html#database-settings)

## Notes for Tool Developers and Integrators

### UTF-8 Characters and Spaces in File Names

UTF-8 characters in filenames are now preserved when downloaded.

Dataverse installations will no longer replace spaces in file names of downloaded files with the + character. If your tool or integration has any special handling around this, you may need to make further adjustments to maintain backwards compatibility while also supporting Dataverse installations on 5.4+.

Note that this follows a change from 5.1 that only corrected this for installations running with S3 storage. This makes the behavior consistent across installations running all types of file storage.

## Complete List of Changes

For the complete list of code changes in this release, see the [5.4 Milestone](https://github.com/IQSS/dataverse/milestone/94?closed=1) in Github.

For help with upgrading, installing, or general questions please post to the [Dataverse Community Google Group](https://groups.google.com/forum/#!forum/dataverse-community) or email support@dataverse.org.

## Installation

If this is a new installation, please see our [Installation Guide](https://guides.dataverse.org/en/5.4/installation/).

## Upgrade Instructions

0\. These instructions assume that you've already successfully upgraded from Dataverse Software 4.x to Dataverse Software 5 following the instructions in the [Dataverse Software 5 Release Notes](https://github.com/IQSS/dataverse/releases/tag/v5.0). After upgrading from the 4.x series to 5.0, you should progress through the other 5.x releases before attempting the upgrade to 5.4.

1\. Upgrade to Java 11.

2\. Upgrade to Solr 8.8.1.

If you are running Payara as a non-root user (and you should be!), **remember not to execute the commands below as root**. Use `sudo` to change to that user first. For example, `sudo -i -u dataverse` if `dataverse` is your dedicated application user.  

In the following commands we assume that Payara 5 is installed in `/usr/local/payara5`. If not, adjust as needed.

`export PAYARA=/usr/local/payara5`

(or `setenv PAYARA /usr/local/payara5` if you are using a `csh`-like shell)

3\. Undeploy the previous version.

- `$PAYARA/bin/asadmin list-applications`
- `$PAYARA/bin/asadmin undeploy dataverse<-version>`

4\. Stop Payara and remove the generated directory

- `service payara stop`
- `rm -rf $PAYARA/glassfish/domains/domain1/generated`

5\. **(only required for installations previously running Dataverse Software 4.x!)** In other words, if you have a domain.xml that **originated under Glassfish 4**, the below JVM Options need to be added. If your Dataverse installation was first installed on the 5.x series, these JVM options should already be present.

In domain.xml:

Remove the following JVM options from the `<config name="server-config"><java-config>` section:

`<jvm-options>-Djava.endorsed.dirs=/usr/local/payara5/glassfish/modules/endorsed:/usr/local/payara5/glassfish/lib/endorsed</jvm-options>`  

`<jvm-options>-Djava.ext.dirs=${com.sun.aas.javaRoot}/lib/ext${path.separator}${com.sun.aas.javaRoot}/jre/lib/ext${path.separator}${com.sun.aas.instanceRoot}/lib/ext</jvm-options>`  

Add the following JVM options to the `<config name="server-config"><java-config>` section:  

`<jvm-options>[9|]--add-opens=java.base/jdk.internal.loader=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-exports=java.base/jdk.internal.ref=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/java.lang=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/java.net=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/java.nio=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/java.util=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/sun.nio.ch=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.management/sun.management=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/sun.net.www.protocol.jrt=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/sun.net.www.protocol.jar=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.naming/javax.naming.spi=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.logging/java.util.logging=ALL-UNNAMED</jvm-options>`  

6\. Start Payara

- `service payara start`
  
7\. Deploy this version.

- `$PAYARA/bin/asadmin deploy dataverse-5.4.war`

8\. Restart payara

- `service payara stop`
- `service payara start`

9\. Reload Citation Metadata Block:

   `wget https://github.com/IQSS/dataverse/releases/download/v5.4/citation.tsv`
   `curl http://localhost:8080/api/admin/datasetfield/load -X POST --data-binary @citation.tsv -H "Content-type: text/tab-separated-values"`

## Additional Release Steps

1\. Confirm that the schema.xml was updated with the new v5.4 version when you updated Solr. 

2\. Run the script updateSchemaMDB.sh to generate updated solr schema files and preserve any other custom fields in your Solr configuration.

For example: (modify the path names as needed)

cd /usr/local/solr-8.8.1/server/solr/collection1/conf
wget https://github.com/IQSS/dataverse/releases/download/v5.4/updateSchemaMDB.sh
chmod +x updateSchemaMDB.sh
./updateSchemaMDB.sh -t .

See <https://guides.dataverse.org/en/5.4/admin/metadatacustomization.html#updating-the-solr-schema> for more information.

3\.  Do a clean reindex by first clearing then indexing. Re-indexing is required to get full-functionality from this change. Please refer to the guides on how to clear and index if needed.

4\. Upgrade Postgres.

- Export your current database with ``pg_dumpall``;
- Install the new version of PostgreSQL; (make sure it's running on the same port, etc. so that no changes are needed in the Payara configuration)
- Re-import the database with ``psql``, as the postgres user.

Consult the PostgreSQL upgrade documentation for more information, for example <https://www.postgresql.org/docs/13/upgrading.html#UPGRADING-VIA-PGDUMPALL>.

5\. Retroactively store original file size

Use the [Datafile Integrity API](https://guides.dataverse.org/en/5.4/api/native-api.html#datafile-integrity) to ensure that the sizes of all original files are stored in the database.

6\. DB Cleanup for Superusers Releasing without Version Updates

In datasets where a superuser has run the Curate command and the update included a change to the fileaccessrequest flag, those changes would not be reflected appropriately in the published version. This should be a rare occurrence.

Instead of an automated solution, we recommend inspecting the affected datasets and correcting the fileaccessrequest flag as appropriate. You can identify the affected datasets this via a query, which is available in the folder here:

<https://github.com/IQSS/dataverse/raw/develop/scripts/issues/7687/>

7\. (Optional, but recommended) DB Cleanup for Saved Searches and Linked Objects

Perform the DB Cleanup for Saved Searches and Linked Objects, summarized in the "Notes for Dataverse Installation Administrators" section above.

8\. Take a backup of the Worldmap links, if any.

9\. (Only required if custom metadata blocks are used in your Dataverse installation) Update any custom metadata blocks:

In the .tsv for any custom metadata blocks, for any subfield that has a required value of TRUE, find the corresponding parent field and change its required value to TRUE.

Note: As there is an accompanying Flyway script that updates the values directly in the database, you do not need to reload these metadata .tsv files via API, unless you make additional changes, e.g set some compound fields to be conditionally required.
