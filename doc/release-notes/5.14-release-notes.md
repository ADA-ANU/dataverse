# Dataverse Software 5.14

This release brings new features, enhancements, and bug fixes to the Dataverse software. Thank you to all of the community members who contributed code, suggestions, bug reports, and other assistance across the project.

## Release Highlights

### For installations using MDC (Make Data Count), it is now possible to display both the MDC metrics and the legacy access counts, generated before MDC was enabled.

This is enabled via the new setting `:MDCStartDate` that specifies the cutoff date. If a dataset has any legacy access counts collected prior to that date, those numbers will be displayed in addition to the any MDC numbers recorded since then. (PR #6543)

### An API endpoint for deleting a file is finally available

Support for deleting files using native API: http://preview.guides.gdcc.io/en/develop/api/native-api.html#deleting-files (PR #9383)

### Changes to PID Provider JVM Settings

In prepration for a future feature to use multiple PID providers at the same time, all JVM settings for PID providers
have been enabled to be configured using MicroProfile Config. In the same go, they were renamed to match the name
of the provider to be configured.

Please watch your log files for deprecation warnings. Your old settings will be picked up, but you should migrate
to the new names to avoid unnecessary log clutter and get prepared for more future changes. An example message
looks like this:

```
[#|2023-03-31T16:55:27.992+0000|WARNING|Payara 5.2022.5|edu.harvard.iq.dataverse.settings.source.AliasConfigSource|_ThreadID=30;_ThreadName=RunLevelControllerThread-1680281704925;_TimeMillis=1680281727992;_LevelValue=900;|
   Detected deprecated config option doi.username in use. Please update your config to use dataverse.pid.datacite.username.|#]
```

Here is a list of the new settings:

- dataverse.pid.datacite.mds-api-url
- dataverse.pid.datacite.rest-api-url
- dataverse.pid.datacite.username
- dataverse.pid.datacite.password
- dataverse.pid.handlenet.key.path
- dataverse.pid.handlenet.key.passphrase
- dataverse.pid.handlenet.index
- dataverse.pid.permalink.base-url
- dataverse.pid.ezid.api-url
- dataverse.pid.ezid.username
- dataverse.pid.ezid.password

See also http://preview.guides.gdcc.io/en/develop/installation/config.html#persistent-identifiers-and-publishing-datasets (multiple PRs: #8823-#8828)

### Signposting for Dataverse

This release adds [Signposting](https://signposting.org/) support to Dataverse to improve machine discoverability of datasets and files. (PR #8424)

The following MicroProfile Config options are now available (these can be treated as JVM options):

- dataverse.signposting.level1-author-limit
- dataverse.signposting.level1-item-limit


### Permalinks support

Dataverse now optionally supports PermaLinks, a type of persistent identifier that does not involve a global registry service. PermaLinks are appropriate for Intranet deployment and catalog use cases. (PR #8674)


### Creating datasets with incomplete metadata through API

It is now possible to create a dataset with some nominally mandatory metadata fields left unpopulated - to accommodate a special use case by a Dataverse instance (see issue #8822 for more detail; PR #8940)

The create dataset API call (POST to /api/dataverses/#dataverseId/datasets) is extended with the "doNotValidate" parameter. However, in order to be able to create a dataset with incomplete metadata, the solr configuration must be updated first with the new "schema.xml" file (do not forget to run the metadata fields update script when you use custom metadata). Reindexing is optional, but recommended. Also, even when this feature is not used, it is recommended to update the solar configuration and reindex the metadata. Finally, this new feature can be activated with the "dataverse.api.allow-incomplete-metadata" JVM option.

You can also enable a valid/incomplete metadata filter in the "My Data" page using the "dataverse.ui.show-validity-filter" JVM option. By default, this filter is not shown. When you wish to use this filter, you must reindex the datasets first, otherwise datasets with valid metadata will not be shown in the results.

It is not possible to publish datasets with incomplete or incomplete metadata. By default, you also cannot send such datasets for review. If you wish to enable sending for review of datasets with incomplete metadata, turn on the "dataverse.ui.allow-review-for-incomplete" JVM option.

In order to customize the wording and add translations to the UI sections extended by this feature, you can edit the "Bundle.properties" file and the localized versions of that file. The property keys used by this feature are:
- incomplete
- valid
- dataset.message.incomplete.warning
- mydataFragment.validity
- dataverses.api.create.dataset.error.mustIncludeAuthorName

### Registering PIDs for files in select collections

It is now possible to configure registering PIDs for files in individual collections.

For example, registration of PIDs for files can be enabled in a specific collection when it is disabled instance-wide. Or it can be disabled in specific collections where it is enabled by default. See the [:FilePIDsEnabled](https://guides.dataverse.org/en/latest/installation/config.html#filepidsenabled) section of the Configuration guide for details. (PR #9614)

### Mechanism Added for Adding External Exporters

It is now possible for third parties to develop and share code to provide new metadata export formats for Dataverse. Export formats can be made available via the Dataverse UI and API or configured for use in Harvesting. Dataverse now provides developers with a separate dataverse-spi JAR file that contains the Java interfaces and classes required to create a new metadata Exporter. Once a new Exporter has been created and packaged as a JAR file, administrators can use it by specifying a local directory for third party Exporters, dropping then Exporter JAR there, and restarting Payara. This mechanism also allows new Exporters to replace any of Dataverse's existing metadata export formats. (PR #9175)

#### Backward Incompatibilities

**TODO: add below**

Care should be taken when replacing Dataverse's internal metadata export formats as third party code, including other third party Exporters may depend on the contents of those export formats. When replacing an existing format, one must also remember to delete the cached metadata export files or run the reExport command for the metadata exports of existing datasets to be updated.

#### New JVM/MicroProfile Settings

dataverse.spi.export.directory - specifies a directory, readable by the Dataverse server. Any Exporter JAR files placed in this directory will be read by Dataverse and used to add/replace the specified metadata format.

### Handling of license information fixed in the API

(PR #9568)

**TODO: add this under "backward incompatibility"**

When publishing a dataset via API, it now requires the dataset to either have a standard license configured, or have valid Custom Terms of Use (if allowed by the instance). Attempting to publish a dataset without such **will fail with an error message**. This introduces a backward incompatibility, and if you have scripts that automatically create, update and publish datasets, this last step may start failing. Because, unfortunately, there were some problems with the datasets APIs that made it difficult to manage licenses, so an API user was likely to end up with a dataset missing either of the above. In this release we have addressed it by making the following fixes:

We fixed the incompatibility between the format in which license information was *exported* in json, and the format the create and update APIs were expecting it for *import* (https://github.com/IQSS/dataverse/issues/9155). This means that the following json format can now be imported:
```
"license": {
   "name": "CC0 1.0",
   "uri": "http://creativecommons.org/publicdomain/zero/1.0"
}
```
However, for the sake of backward compatibility the old format
```
"license" : "CC0 1.0"
```
will be accepted as well.

We have added the default license (CC0) to the model json file that we provide and recommend to use as the model in the Native API Guide (https://github.com/IQSS/dataverse/issues/9364). 

And we have corrected the misleading language in the same guide where we used to recommend to users that they select, edit and re-import only the `.metadataBlocks` fragment of the json metadata representing the latest version. There are in fact other useful pieces of information that need to be preserved in the update (such as the `"license"` section above). So the recommended way of creating base json for updates via the API is to select *everything but* the `"files"` section, with (for example) the following `jq` command:

```
jq '.data | del(.files)'
```

Please see the [Update Metadata For a Dataset](https://guides.dataverse.org/en/latest/api/native-api.html#update-metadata-for-a-dataset) section of our Native Api guide for more information. 


### Changes and fixes in this release not already mentioned above include:

- A date column has been added to the restricted file access request overview, indicating when the earliest request by that user was made. An issue was fixed where where the request list was not updated when a request was approved or rejected. (PR #9257)
- A feature flag called "api-session-auth" has been added temporarily to aid in the development of the new frontend (#9063) but will be removed once bearer tokens (#9229) have been implemented. There is a security risk (CSRF) in enabling this flag! Do not use it in production! For more information, see http://preview.guides.gdcc.io/en/develop/installation/config.html#feature-flags
- Changes made in v5.13 and v5.14 in multiple PRs to improve the embedded Schema.org metadata in dataset pages will only be propagated to the Schema.Org JSON-LD metadata export if a reExportAll() is done. (PR #9102)
- TODO: The 5.14 release notes should include the standard instructions for doing a reExportAll after updating the code, on account of the item above. (L.A.)
- It is now possible to write external vocabulary scripts that target a single child field in a metadata block. Example scripts are now available at https://github.com/gdcc/dataverse-external-vocab-support that can be configured to support lookup from the Research Orgnaization Registry (ROR) for the Author Affiliation Field and for the CrossRef Funding Registry (Fundreg) in the Funding Information/Agency field, both in the standard Citation metadata block. Application if these scripts to other fields, and the development of other scripts targetting child fields are now possible (PR #9402)

## New JVM Options and MicroProfile Config Options

**TODO: the section below is from 5.13; still needs to be updated for 5.14 (L.A.)**

The following JVM option is now available:

- `dataverse.personOrOrg.assumeCommaInPersonName` - the default is false

The following MicroProfile Config options are now available (these can be treated as JVM options):

- `dataverse.files.uploads` - alternative storage location of generated temporary files for UI file uploads
- `dataverse.api.signing-secret` - used by signed URLs
- `dataverse.solr.host`
- `dataverse.solr.port`
- `dataverse.solr.protocol`
- `dataverse.solr.core`
- `dataverse.solr.path`
- `dataverse.rserve.host`

The following existing JVM options are now available via MicroProfile Config:

- `dataverse.siteUrl`
- `dataverse.fqdn`
- `dataverse.files.directory`
- `dataverse.rserve.host`
- `dataverse.rserve.port`
- `dataverse.rserve.user`
- `dataverse.rserve.password`
- `dataverse.rserve.tempdir`

## Notes for Developers and Integrators

See the "Backward Incompatibilities" section below.

## Backward Incompatibilities

**TODO: (L.A.)**


## Complete List of Changes

For the complete list of code changes in this release, see the [5.14 milestone](https://github.com/IQSS/dataverse/milestone/108?closed=1) on GitHub.

## Installation

If this is a new installation, please see our [Installation Guide](https://guides.dataverse.org/en/5.14/installation/). Please don't be shy about [asking for help](https://guides.dataverse.org/en/5.14/installation/intro.html#getting-help) if you need it!

After your installation has gone into production, you are welcome to add it to our [map of installations](https://dataverse.org/installations) by opening an issue in the [dataverse-installations](https://github.com/IQSS/dataverse-installations) repo.



## Upgrade Instructions

0\. These instructions assume that you've already successfully upgraded from version 4.x to 5.0 of the Dataverse software following the instructions in the [release notes for version 5.0](https://github.com/IQSS/dataverse/releases/tag/v5.0). After upgrading from the 4.x series to 5.0, you should progress through the other 5.x releases before attempting the upgrade to 5.14.

If you are running Payara as a non-root user (and you should be!), **remember not to execute the commands below as root**. Use `sudo` to change to that user first. For example, `sudo -i -u dataverse` if `dataverse` is your dedicated application user.

In the following commands we assume that Payara 5 is installed in `/usr/local/payara5`. If not, adjust as needed.

`export PAYARA=/usr/local/payara5`

(or `setenv PAYARA /usr/local/payara5` if you are using a `csh`-like shell)

1\. Undeploy the previous version.

- `$PAYARA/bin/asadmin list-applications`
- `$PAYARA/bin/asadmin undeploy dataverse<-version>`

2\. Stop Payara and remove the generated directory

- `service payara stop`
- `rm -rf $PAYARA/glassfish/domains/domain1/generated`

3\. Start Payara

- `service payara start`

4\. Deploy this version.

- `$PAYARA/bin/asadmin deploy dataverse-5.14.war`

5\. Restart Payara

- `service payara stop`
- `service payara start`

6\. Reload citation metadata block (**TODO: may not be necessary, and/or another block may need to be updated**)

- `wget https://github.com/IQSS/dataverse/releases/download/v5.14/citation.tsv`
- `curl http://localhost:8080/api/admin/datasetfield/load -X POST --data-binary @citation.tsv -H "Content-type: text/tab-separated-values"`

If you are running an English-only installation, you are finished with the citation block. Otherwise, download the updated citation.properties file and place in the [`dataverse.lang.directory`](https://guides.dataverse.org/en/5.14/installation/config.html#configuring-the-lang-directory).

- `wget https://github.com/IQSS/dataverse/releases/download/v5.14/citation.properties`
- `cp citation.properties /home/dataverse/langBundles`

7\. Replace Solr schema.xml (**TODO: may not be necessary for 5.14) See specific instructions below for those installations without custom metadata blocks (1a) and those with  custom metadata blocks  (1b).

Note: with this release support for indexing of the experimental workflow metadata block has been removed from the standard schema.xml. 
If you are using the workflow metadata block be sure to follow the instructions in step 7b) below to maintain support for indexing workflow metadata.

7a\. For installations without custom or experimental metadata blocks:

- Stop Solr instance (usually service solr stop, depending on Solr installation/OS, see the [Installation Guide](https://guides.dataverse.org/en/5.14/installation/prerequisites.html#solr-init-script)

- Replace schema.xml

  - `cp /tmp/dvinstall/schema.xml /usr/local/solr/solr-8.11.1/server/solr/collection1/conf`

- Start solr instance (usually service solr start, depending on Solr/OS)

7b\. For installations with custom or experimental metadata blocks:

- Stop solr instance (usually service solr stop, depending on solr installation/OS, see the [Installation Guide](https://guides.dataverse.org/en/5.14/installation/prerequisites.html#solr-init-script)

- Edit the following line to your schema.xml (to indicate that productionPlace is now multiValued='true"):

    `<field name="productionPlace" type="string" stored="true" indexed="true" multiValued="true"/>`

- Add the following lines to your schema.xml to add support for geospatial indexing:

    `<!-- Dataverse geospatial search -->`
    `<!-- https://solr.apache.org/guide/8_11/spatial-search.html#rpt -->`
    `<field name="geolocation" type="location_rpt" multiValued="true" stored="true" indexed="true"/>`
    `<!-- https://solr.apache.org/guide/8_11/spatial-search.html#bboxfield -->`
    `<field name="boundingBox" type="bbox" multiValued="true" stored="true" indexed="true"/>`
    `<!-- Dataverse - per GeoBlacklight, adding field type for bboxField that enables, among other things, overlap ratio calculations -->`
    `<fieldType name="bbox" class="solr.BBoxField"
           geo="true" distanceUnits="kilometers" numberType="pdouble" />`
    **TODO: why are we recommending editing the schema file by hand, instead of re-running the update script?**
     
- Restart Solr instance (usually service solr start, depending on solr/OS)

### TODO: any optional upgrade steps to be added here

