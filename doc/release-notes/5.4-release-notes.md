# Dataverse 5.4

This release brings new features, enhancements, and bug fixes to Dataverse. Thank you to all of the community members who contributed code, suggestions, bug reports, and other assistance across the project.

## Release Highlights

### Search with non-ascii characters

Many languages include characters that have close analogs in ascii, e.g. (á, à, â, ç, é, è, ê, ë, í, ó, ö, ú, ù, û, ü…). This release changes the default Solr configuration to allow search to match words based on these associations, e.g. a search for Mercè would match the word Merce in a Dataset, and vice versa. This should generally be helpful, but can result in false positives.,e.g. "canon" will be found searching for "cañon".

### Deactivate Users API, Get User Traces API, Revoke Roles API

A new API has been added to deactivate users to prevent them from logging in or otherwise being active in the system. Deactivating a user is an alternative to deleting a user, especially when the latter is not possible due to the amount of interaction the user has had with the system. In order to learn more about a user before deleting, deactivating, or merging, a new "get user traces" API is available that will show objects created, roles, group memberships, and more. Finally, the "remove all roles" button available in the superuser dashboard is now also available via API.

### New File Access API

A new api offers *crawlable* access view of the folders and files within a datset:

```
  /api/datasets/<dataset id>/dirindex/
```

will output a simple html listing, based on the standard Apache
directory index, with Access API download links for individual files,
and recursive calls to the API above for sub-folders. (See the
documentation entry in the guides for more information).

Using this API, ``wget --recursive`` (or similar crawling client) can
be used to download all the files in a dataset, preserving the file
names and folder structure; without having to use the download-as-zip
API. In addition to being faster (zipping is a relatively
resource-intensive operation on the server side), this process can be
restarted if interrupted (with ``wget --continue`` or equivalent) -
unlike zipped multi-file downloads that always have to start from the
beginning.

On a system that uses S3 with download redirects, the individual file
downloads will be handled by S3 directly, without having to be proxied
through the Dataverse application.

### Java 11

The Dataverse software now runs and requires Java 11. This will provide performance and security enhancements, allows developers to take advantage of new and updated Java features, and moves the project to a platform with better longer term support. This upgrade requires a few extra steps in the release process, outlined below.

### Saved Search Performance Improvements

A refactoring has greatly improved Saved Search performance in the application. If your installation has multiple, potentially long-running Saved Searches in place, this greatly improves the probability that those search jobs will complete without timing out.

### Worldmap/Geoconnect Integration Now Obsolete

As of this release, the Geoconnect/Worldmap integration is no longer available. The Harvard University Worldmap is going through a migration process, and instead of updating this code to work with the new infrastructure, the decision was made to pursue future Geospatial exploration/analysis through other tools, following the External Tools Framework in the Dataverse Software.

### Guides Updates

The Dataverse Guides have been updated to follow recent changes to how different terms are used across the Dataverse Project. For more information, see Mercè's note to the community:

<https://groups.google.com/g/dataverse-community/c/pD-aFrpXMPo>

### Conditionally Required Metadata Fields


## Major Use Cases

Newly-supported use cases in this release include:

- Deactivate Users (Issue #xxx, PR #xxx)
- Non-ascii characters
- Users can now replace files in draft datasets. This functionality was previously only available on published datasets. Issue #7149/PR #7337
- Metadata designers can now set subfields of compound fields as **conditionally required**, that is, the field is required if and only if any of its "sibling" fields are entered. For example, Producer Name is now conditionally required in the citation metadata block. A user does not have to enter a Producer, but if they do, they have to enter a Producer Name.

## Notes for Dataverse Installation Administrators

### Java 11 Upgrade

There are some things to note and keep in mind regarding the move to Java 11:

- You should install the JDK/JRE following your usual methods, depending on your operating system. An example of this on a RHEL/CentOS 7 or RHEL/CentOS 8 system is:

    `$ sudo yum remove java-1.8.0-openjdk java-1.8.0-openjdk-devel java-1.8.0-openjdk-headless`  

    `$ sudo yum install java-11-openjdk-devel`  
    
    The `remove` command may provide an error message if -headless isn't installed.

- We targeted and tested Java 11, but 11+ will likely work. Java 11 was targeted because of its long term support.
- If you're moving from a Dataverse installation that was previously running Glassfish 4.x (typically this would be Dataverse Software 4.x), you will need to adjust some JVM options in domain.xml as part of the upgrade process. We've provided these optional steps below. These steps are not required if your first installed Dataverse version was running Payara 5.x (typically Dataverse Software 5.x).

## Conditionally Required Metadata Fields

Prior to this release, when defining metadata for compound fields (via their dataset field types), fields could be either be optional or required, i.e. if required you must always have (at least one) value for that field. For example, Author Name being required means you must have at least one Author with an nonempty Author name.

In order to support more robust metadata (and specifically to resolve #7551), we need to allow a third case: Conditionally Required, that is, the field is required if and only if any of its "sibling" fields are entered. For example, Producer Name is now conditionally required in the citation metadata block. A user does not have to enter a Producer, but if they do, they have to enter a Producer Name.

This change required some modifications to how "required" is defined in the metadata .tsv files (for compound fields).

Prior to this release, the value of required for the parent compound field did not matter and so was set to false.

Going forward:

- For optional, the parent compound field would be required = false and all children would be required = false.
- For required, the parent compound field would be required = true and at least one child would be required = true.
- For conditionally required, the parent compound field would be required = false and at least one child would be required = true.

This release updates the citation .tsv file that is distributed with the software for the required parent compound fields (e.g. author), as well as sets Producer Name to be conditionally required. No other distributed .tsv files were updated, as they did not have any required compound values.

**If you have created any custom metadata .tsv files**, you will need to make the same (type of) changes there.

### PostgreSQL Version Support

Up until this release our installation guide "strongly recommended" to install PostgreSQL v. 9.6. While that version is known to be very stable, it is nearing its end-of-life (in Nov. 2021). Dataverse Software has now been tested with versions up to 13. If you decide to upgrade PostgreSQL, the tested and recommended way of doing that is as follows:

- Export your current database with ``pg_dumpall``;
- Install the new version of PostgreSQL; (make sure it's running on the same port, etc. so that no changes are needed in the Payara configuration)
- Re-import the database with ``psql``, as the postgres user.

Consult the PostgreSQL upgrade documentation for more information, for example https://www.postgresql.org/docs/13/upgrading.html#UPGRADING-VIA-PGDUMPALL.

### Retroactively Store Original File Size

Beginning in Dataverse Software 4.10, the size of the saved original file (for an ingested tabular datafile) was stored in the database. For files added before this change, we provide an API that retrieves and permanently stores the sizes for any already existing saved originals. See [Datafile Integrity API](https://guides.dataverse.org/en/5.4/api/native-api.html#datafile-integrity) for more information.

This was documented as a step in previous release notes, but we are noting it in these release notes to give it more visibility.

### DB Cleanup for Saved Searches

A previous version of dataverse changed the indexing logic so that when a user links a dataverse, its children are also indexed as linked. This means that the children do not need to be separately linked, and in this version we removed the logic that creates a saved search to create those links when a dataverse is linked.

We recommend cleaning up the db to a) remove these saved searches and b) remove the links for the objects. We can do this via a few queries, which are available in the folder here:

https://github.com/IQSS/dataverse/raw/develop/scripts/issues/7398/

There are four sets of queries available, and they should be run in this order:

- ss_for_deletion.txt to identify the Saved Searches to be deleted
- delete_ss.txt to delete the Saved Searches identified in the previous query
- dld_for_deletion.txt to identify the linked datasets and dataverses to be deleted
- delete_dld.txt to delete the linked datasets and dataverses identified in the previous queries

Note: removing these saved searches and links should not affect what users will see as linked due to the aforementioned indexing change. Similarly, not removing these saved searches and links should not affect anything, but is a cleanup of unnecessary rows in the database.

### New JVM and DB Options

#### New JVM Options

For installations that were previously running on Dataverse Software 4.x, the following JVM Options have been added in support of Java 11:

- `<jvm-options>[9|]--add-opens=java.base/jdk.internal.loader=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-exports=java.base/jdk.internal.ref=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.base/java.lang=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.base/java.net=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.base/java.nio=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.base/java.util=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.base/sun.nio.ch=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.management/sun.management=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.base/sun.net.www.protocol.jrt=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.base/sun.net.www.protocol.jar=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.naming/javax.naming.spi=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED</jvm-options>`
- `<jvm-options>[9|]--add-opens=java.logging/java.util.logging=ALL-UNNAMED</jvm-options>`

## Notes for Tool Developers and Integrators

### UTF-8 Characters and Spaces in File Names

UTF-8 characters in filenames are now preserved when downloaded.

Dataverse Installations will no longer replace spaces in file names of downloaded files with the + character. If your tool or integration has any special handling around this, you may need to make further adjustments to maintain backwards compatibility while also supporting Dataverse installations on 5.4+.

Note that this follows a change from 5.1 that only corrected this for installations running with S3 storage. This makes the behavior consistent across installations running all types of file storage.

## Complete List of Changes

For the complete list of code changes in this release, see the [5.4 Milestone](https://github.com/IQSS/dataverse/milestone/94?closed=1) in Github.

For help with upgrading, installing, or general questions please post to the [Dataverse Google Group](https://groups.google.com/forum/#!forum/dataverse-community) or email support@dataverse.org.

## Installation

If this is a new installation, please see our [Installation Guide](https://guides.dataverse.org/en/5.3/installation/).

## Upgrade Instructions

0\. These instructions assume that you've already successfully upgraded from Dataverse 4.x to Dataverse 5 following the instructions in the [Dataverse 5 Release Notes](https://github.com/IQSS/dataverse/releases/tag/v5.0). After upgrading from the 4.x series to 5.0, you should progress through the other 5.x releases before attempting the upgrade to 5.4.

1\. Undeploy the previous version.

- `<payara install path>/bin/asadmin list-applications`
- `<payara install path>/bin/asadmin undeploy dataverse<-version>`

(where `<payara install path>` is where Payara 5 is installed, for example: `/usr/local/payara5`)

2\. Stop Payara and remove the generated directory

- `service payara stop`
- remove the generated directory: 
`rm -rf <payara install path>/payara/domains/domain1/generated`

3\. (only required for installations previously running on Dataverse Software 4.x)

In domain.xml:

Remove the following JVM options from the domain><configs><config name-"server-config"><java-config> element:

`<jvm-options>-Djava.endorsed.dirs=/usr/local/payara5/glassfish/modules/endorsed:/usr/local/payara5/glassfish/lib/endorsed</jvm-options>`  

`<jvm-options>-Djava.ext.dirs=${com.sun.aas.javaRoot}/lib/ext${path.separator}${com.sun.aas.javaRoot}/jre/lib/ext${path.separator}${com.sun.aas.instanceRoot}/lib/ext</jvm-options>`  

Add the following JVM options to the domain><configs><config name-"server-config"><java-config> element:  

`<jvm-options>[9|]--add-opens=java.base/jdk.internal.loader=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-exports=java.base/jdk.internal.ref=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/java.lang=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/java.net=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/java.nio=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/java.util=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/sun.nio.ch=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.management/sun.management=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/sun.net.www.protocol.jrt=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.base/sun.net.www.protocol.jar=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.naming/javax.naming.spi=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED</jvm-options>`  

`<jvm-options>[9|]--add-opens=java.logging/java.util.logging=ALL-UNNAMED</jvm-options>`  

4\. Start Payara

- `service payara start`
  
5\. Deploy this version.

- `<payara install path>/bin/asadmin deploy dataverse-5.4.war`

6\. Restart payara

- `service payara stop`
- `service payara start`

Additional Release Steps

1\. Retroactively store original file size

Use the [Datafile Integrity API](https://guides.dataverse.org/en/5.4/api/native-api.html#datafile-integrity) to ensure that the sizes of all original files are stored in the database.

2\. (Optional, but recommended) DB Cleanup

Perform the DB Cleanup for Saved Searches and Linked Objects, summarized in the "Notes for Dataverse Installation Administrators" section above.

3\. Take a backup of the Worldmap links, if any.

4\. Reload Citation Metadata Block:

   `wget https://github.com/IQSS/dataverse/releases/download/v5.4/citation.tsv`
   `curl http://localhost:8080/api/admin/datasetfield/load -X POST --data-binary @citation.tsv -H "Content-type: text/tab-separated-values"`

5\. Update any custom metadata blocks (if used):

For any subfield that has a required value of TRUE, find the corresponding parent field and change its required value to TRUE.

Note: As there is an accompanying Flyway script that updates the values directly in the database, you do not need to reload these metadata .tsv files via API, unless you make additional changes, e.g set some compound fields to be conditionally required.