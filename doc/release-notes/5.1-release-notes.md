# Dataverse 5.1

This release brings new features, enhancements, and bug fixes to Dataverse. Thank you to all of the community members who contributed code, suggestions, bug reports, and other assistance across the project.

## Release Highlights

### Large File Upload for Installations Using AWS S3

The added support for multipart upload through the API (Issue #6763) will allow files larger than 5 GB to be uploaded to Dataverse when an installation is running on AWS S3. Previously, only non-AWS S3 storage configurations would allow uploads larger than 5 GB.

### Dataset-Specific Stores

In previous releases, configuration options were added that allow each dataverse to have a specific store enabled. This release adds even more granularity, with the ability to set a dataset-level store.

## Major Use Cases

Newly-supported use cases in this release include:

- Users can now upload files larger than 5 GB on installations running AWS S3 (Issue #6763, PR #6995)
- Administrators will now be able to specify a store at the dataset level in addition to the Dataverse level (Issue #6872, PR #7272)
- Users will have their dataset's directory structure retained when uploading a dataset with shapefiles (Issue #6873, PR #7279)
- Users will now be able to download zip files through the experimental Zipper service when the set of downloaded files have duplicate names (Issue [#80](https://github.com/IQSS/dataverse.harvard.edu/issues/80), PR #7276)
- Users will now be able to download zip files with the proper file structure through the experiment Zipper service (Issue #7255, PR #7258)
- Administrators will be able use a new API to keep the database and Solr index in sync (Issue #4225, PR #7211)

## Notes for Dataverse Installation Administrators

### New API for setting a Dataset-level Store

- New API available for setting a dataset store

### New API for keeping Solr records in sync

From time to time, "stale" records may end up in Solr. This can affect the successful loading of a search results page on which the stale record exists. New API for Solr records

### Documentation for Purging the Ingest Queue

At times, it may be necessary to cancel long-running Ingest jobs in the interest of system stability. The Troubleshooting section of the [Admin Guide](http://guides.dataverse.org/en/5.1/admin/) has specific steps.

## Notes for Tool Developers and Integrators

### File Name change

## Complete List of Changes

For the complete list of code changes in this release, see the [5.1 Milestone](https://github.com/IQSS/dataverse/milestone/90?closed=1) in Github.

For help with upgrading, installing, or general questions please post to the [Dataverse Google Group](https://groups.google.com/forum/#!forum/dataverse-community) or email support@dataverse.org.

## Installation

If this is a new installation, please see our [Installation Guide](http://guides.dataverse.org/en/5.1/installation/)

## Upgrade Instructions

### Upgrade from Glassfish 4.1 to Payara 5

The instructions below describe the upgrade procedure based on moving an existing glassfish4 domain directory under Payara. We recommend this method instead of setting up a brand-new Payara domain using the installer because it appears to be the easiest way to recreate your current configuration and preserve all your data.

1. Download Payara, v5.2020.2 as of this writing:

   `curl -L -O https://github.com/payara/Payara/releases/download/payara-server-5.2020.2/payara-5.2020.2.zip`
   `sha256sum payara-5.2020.2.zip`
      1f5f7ea30901b1b4c7bcdfa5591881a700c9b7e2022ae3894192ba97eb83cc3e

2. Unzip it somewhere (/usr/local is a safe bet)

   `sudo unzip payara-5.2020.2.zip -d /usr/local/`

3. Copy the Postgres driver to /usr/local/payara5/glassfish/lib

   `sudo cp /usr/local/glassfish4/glassfish/lib/postgresql-42.2.9.jar /usr/local/payara5/glassfish/lib/`

4. Move payara5/glassfish/domains/domain1 out of the way

   `sudo mv /usr/local/payara5/glassfish/domains/domain1 /usr/local/payara5/glassfish/domains/domain1.orig`

5. Undeploy the Dataverse web application (if deployed; version 4.20 is assumed in the example below)

   `sudo /usr/local/glassfish4/bin/asadmin list-applications`
   `sudo /usr/local/glassfish4/bin/asadmin undeploy dataverse-4.20`

6. Stop Glassfish; copy domain1 to Payara

   `sudo /usr/local/glassfish4/bin/asadmin stop-domain`
   `sudo cp -ar /usr/local/glassfish4/glassfish/domains/domain1 /usr/local/payara5/glassfish/domains/`

7. Remove the Glassfish cache directories

   `sudo rm -rf /usr/local/payara5/glassfish/domains/domain1/generated/`  `sudo rm -rf /usr/local/payara5/glassfish/domains/domain1/osgi-cache/`

8. In domain.xml:

 Replace the -XX:PermSize and -XX:MaxPermSize JVM options with -XX:MetaspaceSize and -XX:MaxMetaspaceSize.

   <jvm-options>-XX:MetaspaceSize=256m</jvm-options>
   <jvm-options>-XX:MaxMetaspaceSize=512m</jvm-options>

Add the below JVM options beneath the -Ddataverse settings:  

   <jvm-options>-Dfish.payara.classloading.delegate=false</jvm-options>
   <jvm-options>-XX:+UseG1GC</jvm-options>
   <jvm-options>-XX:+UseStringDeduplication</jvm-options>
   <jvm-options>-XX:+DisableExplicitGC</jvm-options>

9. Change any full pathnames /usr/local/glassfish4/... to /usr/local/payara5/... or whatever it is in your case. (Specifically check the -Ddataverse.files.directory and -Ddataverse.files.file.directory JVM options)

10.  In domain1/config/jhove.conf, change the hard-coded /usr/local/glassfish4 path, as above.

(Optional): If you renamed your service account from glassfish to payara or appserver, update the ownership permissions. The Installation Guide recommends a service account of `dataverse`:

   `sudo chown -R dataverse /usr/local/payara5/glassfish/domains/domain1`
   `sudo chown -R dataverse /usr/local/payara5/glassfish/lib`

11. You will also need to check that the service account has write permission on the files directory, if they are located outside the old Glassfish domain. And/or make sure the service account has the correct AWS credentials, if you are using S3 for storage.

12. Finally, start Payara:

   `sudo -u dataverse /usr/local/payara5/bin/asadmin start-domain`

13. Deploy the Dataverse 5 warfile:

   `sudo -u dataverse /usr/local/payara5/bin/asadmin deploy /path/to/dataverse-5.0.war`

14. Then restart Payara:

   `sudo -u dataverse /usr/local/payara5/bin/asadmin stop-domain`
   `sudo -u dataverse /usr/local/payara5/bin/asadmin start-domain`

### Additional Upgrade Steps

1. Update Astrophysics Metadata Block (if used)

   `wget https://github.com/IQSS/dataverse/releases/download/5.0/astrophysics.tsv`
   `curl http://localhost:8080/api/admin/datasetfield/load -X POST --data-binary @astrophysics.tsv -H "Content-type: text/tab-separated-values"` 

2. (Recommended) Run ReExportall to update JSON Exports  

   <http://guides.dataverse.org/en/5.0/admin/metadataexport.html?highlight=export#batch-exports-through-the-api>

3. (Required for installations using DataCite) Add the JVM option doi.dataciterestapiurlstring

For production environments:

   `/usr/local/payara5/bin/asadmin create-jvm-options "\-Ddoi.dataciterestapiurlstring=https\://api.datacite.org"`
   
For test environments: 

   `/usr/local/payara5/bin/asadmin create-jvm-options "\-Ddoi.dataciterestapiurlstring=https\://api.test.datacite.org"`

The JVM option `doi.mdcbaseurlstring` should be deleted if it was previously set, for example:

   `/usr/local/payara5/bin/asadmin delete-jvm-options "\-Ddoi.mdcbaseurlstring=https\://api.test.datacite.org"`
     
4. (Recommended for installations using DataCite) Pre-register DOIs

Execute the script described in the section "Dataverse Installations Using DataCite: Upgrade Action Recommended" earlier in the Release Note. 

Please consult the earlier sections of the Release Note for any additional configuration options that may apply to your installation. 
